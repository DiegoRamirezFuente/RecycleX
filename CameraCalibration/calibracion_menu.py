import os
import cv2
import numpy as np
import glob
import json
from scipy.spatial.transform import Rotation as R

# --- Configuraci√≥n global ---
output_dir = "calib_images"
camera_params_file = "camera_params.json"
handeye_file = "handeye_params.json"
tcp_poses_file = "tcp_poses.json"  # Nuevo archivo para guardar poses del TCP
chessboard_size = (7, 7)
square_size = 0.025
predefined_z = 0.3  # Altura preestablecida para el TCP sobre el tap√≥n
tcp_to_cam_offset = [-0.074, 0.0, -0.035]  # x, y, z en metros
tcp_to_cam_rot_offset = [0.6450934905627825, -3.0645195408800863, 0.0076346200951948485]  # rx, ry, rz en radianes
# ----------------------------

def capturar_imagenes():
    os.makedirs(output_dir, exist_ok=True)
    
    # Verificar si ya hay poses guardadas
    tcp_poses = []
    if os.path.exists(tcp_poses_file):
        with open(tcp_poses_file, 'r') as f:
            tcp_poses = json.load(f)
    
    cap = cv2.VideoCapture(0)

    if not cap.isOpened():
        print("‚ùå Error al abrir la c√°mara.")
        return

    print("\n=== CAPTURA DE IM√ÅGENES ===")
    print("1. Coloca el tablero en una posici√≥n")
    print("2. Mueve el robot a la posici√≥n deseada")
    print("3. Introduce las coordenadas TCP actuales")
    print("4. Presiona 'c' para capturar (con patr√≥n visible)")
    print("5. 'q' para terminar\n")

    img_count = len(os.listdir(output_dir))
    while True:
        ret, frame = cap.read()
        if not ret:
            print("‚ö† Error al leer la imagen de la c√°mara.")
            break

        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        ret_chess, corners = cv2.findChessboardCorners(gray, chessboard_size, None)

        display_frame = frame.copy()
        if ret_chess:
            cv2.drawChessboardCorners(display_frame, chessboard_size, corners, ret_chess)

        cv2.imshow("Vista previa", display_frame)
        key = cv2.waitKey(1) & 0xFF

        if key == ord('c') and ret_chess:
            # Pedir coordenadas TCP actuales
            print("Introduce las coordenadas TCP actuales (x y z rx ry rz):")
            try:
                tcp_pose = list(map(float, input("> ").split()))
                if len(tcp_pose) != 6:
                    raise ValueError
                
                img_count += 1
                filename = os.path.join(output_dir, f"calib_{img_count:03d}.jpg")
                cv2.imwrite(filename, frame)
                tcp_poses.append(tcp_pose)
                
                # Guardar las poses actualizadas
                with open(tcp_poses_file, 'w') as f:
                    json.dump(tcp_poses, f, indent=4)
                
                print(f"‚úÖ Imagen {img_count} guardada con pose TCP: {tcp_pose}")
            except:
                print("‚úò Formato incorrecto. Usa: x y z rx ry rz")
        elif key == ord('c'):
            print("‚úò No se detect√≥ el patr√≥n. Ajusta el tablero.")
        elif key == ord('q'):
            break

    cap.release()
    cv2.destroyAllWindows()

def calibrar_camara_y_handeye():
    print("\n=== CALIBRACI√ìN COMPLETA ===")
    
    # Cargar poses TCP si existen
    if not os.path.exists(tcp_poses_file):
        print("‚ùå No hay poses TCP guardadas.")
        return None, None, None
    
    with open(tcp_poses_file, 'r') as f:
        tcp_poses = json.load(f)
    
    # Preparar puntos del tablero
    objp = np.zeros((chessboard_size[0]*chessboard_size[1], 3), np.float32)
    objp[:, :2] = np.mgrid[0:chessboard_size[0], 0:chessboard_size[1]].T.reshape(-1, 2) * square_size
    
    objpoints, imgpoints = [], []
    images = glob.glob(os.path.join(output_dir, "*.jpg"))
    
    if len(images) != len(tcp_poses):
        print("‚ùå N√∫mero de im√°genes no coincide con poses TCP.")
        return None, None, None
    
    # Procesar im√°genes
    valid_images = []
    for fname, tcp_pose in zip(images, tcp_poses):
        img = cv2.imread(fname)
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        ret, corners = cv2.findChessboardCorners(gray, chessboard_size, None)
        if ret:
            corners2 = cv2.cornerSubPix(gray, corners, (11,11), (-1,-1),
                        (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001))
            objpoints.append(objp)
            imgpoints.append(corners2)
            valid_images.append((fname, tcp_pose))
            print(f"‚úî Patr√≥n v√°lido en {os.path.basename(fname)}")
        else:
            print(f"‚úò Patr√≥n NO encontrado en {os.path.basename(fname)}")
    
    if len(objpoints) < 3:
        print("‚ö† Se necesitan al menos 3 im√°genes v√°lidas.")
        return None, None, None
    
    # Calibrar c√°mara
    print("üõ† Calibrando c√°mara...")
    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)
    
    if not ret:
        print("‚ùå Fall√≥ la calibraci√≥n de c√°mara.")
        return None, None, None
    
    # Guardar par√°metros de c√°mara
    camera_data = {
        'mtx': mtx.tolist(),
        'dist': dist.tolist()
    }
    with open(camera_params_file, 'w') as f:
        json.dump(camera_data, f, indent=4)
    print(f"‚úÖ Par√°metros de c√°mara guardados en {camera_params_file}")
    
    # Calibrar Hand-Eye
    print("üõ† Calibrando Hand-Eye...")
    R_cam_to_board = [cv2.Rodrigues(rvec)[0] for rvec in rvecs]
    t_cam_to_board = [tvec.reshape(3,1) for tvec in tvecs]

    # Aplicar offset a las poses TCP
    R_tcp_to_cam = R.from_rotvec(tcp_to_cam_rot_offset).as_matrix()
    t_tcp_to_cam = np.array(tcp_to_cam_offset).reshape(3, 1)

    R_base_to_tcp = [R.from_rotvec(pose[3:6]).as_matrix() for _, pose in valid_images]
    t_base_to_tcp = [np.array(pose[:3]).reshape(3,1) for _, pose in valid_images]

    # Convertir de base->tcp a base->cam
    R_base_to_cam = [r_base_tcp @ R_tcp_to_cam for r_base_tcp in R_base_to_tcp]
    t_base_to_cam = [r_base_tcp @ t_tcp_to_cam + t_base_tcp for r_base_tcp, t_base_tcp in zip(R_base_to_tcp, t_base_to_tcp)]

    try:
        R_cam_to_tcp, t_cam_to_tcp = cv2.calibrateHandEye(
            R_gripper2base=R_base_to_cam,  # Usamos las poses convertidas a c√°mara
            t_gripper2base=t_base_to_cam,
            R_target2cam=R_cam_to_board,
            t_target2cam=t_cam_to_board,
            method=cv2.CALIB_HAND_EYE_TSAI
        )
        
        T = {
            'rotation': R_cam_to_tcp.tolist(),
            'translation': t_cam_to_tcp.flatten().tolist()
        }
        
        with open(handeye_file, 'w') as f:
            json.dump(T, f, indent=4)
        
        print(f"‚úÖ Transformaci√≥n c√°mara ‚Üí TCP guardada en {handeye_file}")
        return mtx, dist, T
    except Exception as e:
        print(f"‚ùå Error en calibraci√≥n Hand-Eye: {str(e)}")
        return mtx, dist, None

def calcular_posicion_tcp(mtx, dist, T_cam_to_tcp):
    if T_cam_to_tcp is None:
        print("‚ö† No hay transformaci√≥n Hand-Eye cargada.")
        return
    
    print("\n=== C√ÅLCULO DE POSICI√ìN TCP ===")
    print(f"Altura preestablecida (Z): {predefined_z} m")
    print("Introduce coordenadas del centro del tap√≥n en p√≠xeles (u v):")
    u, v = map(int, input("> ").split())
    
    # Convertir coordenadas de imagen a coordenadas de c√°mara
    fx, fy = mtx[0,0], mtx[1,1]
    cx, cy = mtx[0,2], mtx[1,2]
    
    # 1. Convertir p√≠xeles a coordenadas de c√°mara (sin distorsi√≥n)
    pts = np.array([[[u, v]]], dtype=np.float32)
    pts_undist = cv2.undistortPoints(pts, mtx, dist, P=mtx)
    u_norm, v_norm = pts_undist[0][0]
    
    # 2. Calcular posici√≥n en coordenadas de c√°mara (asumiendo Z conocido)
    X_cam = (u_norm - cx) * predefined_z / fx
    Y_cam = (v_norm - cy) * predefined_z / fy
    point_cam = np.array([X_cam, Y_cam, predefined_z, 1.0])
    
    # 3. Convertir a coordenadas TCP
    T_cam_tcp = np.eye(4)
    T_cam_tcp[:3, :3] = np.array(T_cam_to_tcp['rotation'])
    T_cam_tcp[:3, 3] = np.array(T_cam_to_tcp['translation'])
    point_tcp = T_cam_tcp @ point_cam
    
    # 4. Mostrar resultado (solo posici√≥n, manteniendo orientaci√≥n original)
    print(f"\nüìå Posici√≥n calculada para el TCP:")
    print(f"X: {point_tcp[0]:.4f} m")
    print(f"Y: {point_tcp[1]:.4f} m")
    print(f"Z: {predefined_z:.4f} m (predefinida)")
    print("\nNota: Usa los mismos valores de rotaci√≥n (rx ry rz) que durante la calibraci√≥n")

def main():
    mtx, dist, T_cam_to_tcp = None, None, None
    
    while True:
        print("\n==== MEN√ö PRINCIPAL ====")
        print("1. Capturar im√°genes y poses TCP")
        print("2. Calibrar c√°mara y Hand-Eye")
        print("3. Calcular posici√≥n TCP para tap√≥n")
        print("4. Salir")
        opcion = input("Selecciona una opci√≥n: ")

        if opcion == '1':
            capturar_imagenes()
        elif opcion == '2':
            mtx, dist, T_cam_to_tcp = calibrar_camara_y_handeye()
        elif opcion == '3':
            if mtx is None or dist is None or T_cam_to_tcp is None:
                print("‚ö† Falta calibrar c√°mara y/o hand-eye.")
            else:
                calcular_posicion_tcp(mtx, dist, T_cam_to_tcp)
        elif opcion == '4':
            print("üëã Saliendo...")
            break
        else:
            print("‚ùå Opci√≥n inv√°lida.")
            
if __name__ == "__main__":
    main()